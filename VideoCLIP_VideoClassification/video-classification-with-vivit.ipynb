{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZ_iF3oYHpyv"},"outputs":[],"source":["%mkdir dataset\n","%cd dataset\n","!gdown 1N93rb_uFqKRZ9naX8CXShFt5RJHOmjZH\n","!unzip -q rwf-2000.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BhWsqKQOHpyv"},"outputs":[],"source":["%cd .."]},{"cell_type":"markdown","metadata":{"id":"dEkgxwpUHpyv"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7eGTidAtHpyw"},"outputs":[],"source":["import os\n","import time\n","\n","import torch\n","import torch.nn as nn\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from tqdm import tqdm\n","from transformers import VivitConfig, VivitForVideoClassification\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vI_crYS_Hpyw"},"outputs":[],"source":["import logging\n","\n","logging.getLogger().setLevel(logging.INFO)\n","logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n","LOGGER = logging.getLogger(\"Torch-Cls\")\n","seed = 123\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"h_D3jBlDHpyw"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDLVsXMJHpyw"},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_classes=2, image_size=224, num_frames=15):\n","        super(Model, self).__init__()\n","        cfg = VivitConfig()\n","        cfg.num_classes = num_classes\n","        cfg.image_size = image_size\n","        cfg.num_frames = num_frames\n","\n","        self.vivit = VivitForVideoClassification.from_pretrained(\n","            \"google/vivit-b-16x2-kinetics400\",\n","            config=cfg,\n","            ignore_mismatched_sizes=True,\n","        )\n","\n","    def forward(self, x_3d):\n","        # (bs, C, T, H, W) -> (bs, T, C, H, W)\n","        x_3d = x_3d.permute(0, 2, 1, 3, 4)\n","\n","        out = self.vivit(x_3d)\n","\n","        return out.logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnCaaF94Hpyw","outputId":"905b3ed3-12a0-4b66-8fcd-3d1631550af4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of VivitForVideoClassification were not initialized from the model checkpoint at google/vivit-b-16x2-kinetics400 and are newly initialized because the shapes did not match:\n","- vivit.embeddings.position_embeddings: found shape torch.Size([1, 3137, 768]) in the checkpoint and torch.Size([1, 1373, 768]) in the model instantiated\n","- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([2]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Model has 87293186 parameters\n","torch.Size([1, 2])\n"]}],"source":["# Example of how to use the model\n","model = Model(num_classes=2, num_frames=15)\n","\n","# Check param\n","param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Model has {param} parameters\")\n","\n","# Test the model with a random input (batch_size, channels, frames, height, width)\n","inputs = torch.rand(1, 3, 15, 224, 224)\n","\n","output = model(inputs)\n","\n","print(output.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElJWyZhkHpyw"},"outputs":[],"source":["del model, inputs, output"]},{"cell_type":"markdown","metadata":{"id":"B7-rPk35Hpyw"},"source":["# Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ix_IV-oWHpyw"},"outputs":[],"source":["class VideoDataset(Dataset):\n","    def __init__(self, root_dir, phase=\"train\", transform=None, n_frames=None):\n","        \"\"\"\n","        Args:\n","            root_dir (string): Directory with all the videos (each video as a subdirectory of frames).\n","            transform (callable, optional): Optional transform to be applied on a sample.\n","            n_frames (int, optional): Number of frames to sample from each video, uniformly. If None, use all frames.\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.n_frames = n_frames\n","        self.phase = phase\n","        self.videos, self.labels = self._load_videos()\n","\n","    def _load_videos(self):\n","        videos, labels = [], []\n","        class_id = 0\n","\n","        video_folders = os.listdir(os.path.join(self.root_dir, self.phase))\n","\n","        for folder in video_folders:\n","            video_paths = os.listdir(os.path.join(self.root_dir, self.phase, folder))\n","\n","            for video_path in video_paths:\n","                video_folder = os.path.join(\n","                    self.root_dir, self.phase, folder, video_path\n","                )\n","                frames = sorted(\n","                    (os.path.join(video_folder, f) for f in os.listdir(video_folder)),\n","                    key=lambda f: int(\n","                        \"\".join(filter(str.isdigit, os.path.basename(f)))\n","                    ),\n","                )\n","\n","                if self.n_frames:\n","                    frames = self._uniform_sample(frames, self.n_frames)\n","\n","                videos.append(frames)\n","                labels.append(class_id)\n","\n","            class_id += 1\n","\n","        return videos, labels\n","\n","    def _uniform_sample(self, frames, n_frames):\n","        \"\"\"\n","        Helper method to uniformly sample n_frames from the frames list.\n","        \"\"\"\n","        stride = max(1, len(frames) // n_frames)\n","        sampled = [frames[i] for i in range(0, len(frames), stride)]\n","        return sampled[:n_frames]\n","\n","    def __len__(self):\n","        return len(self.videos)\n","\n","    def __getitem__(self, idx):\n","        video_frames = self.videos[idx]\n","        label = self.labels[idx]\n","        images = []\n","        for frame_path in video_frames:\n","            image = Image.open(frame_path).convert(\"RGB\")\n","            if self.transform:\n","                image = self.transform(image)\n","            images.append(image)\n","\n","        # Stack images along new dimension (sequence length)\n","        data = torch.stack(images, dim=0)\n","\n","        # Rearrange to have the shape (C, T, H, W)\n","        data = data.permute(1, 0, 2, 3)\n","        return data, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kt13SALuHpyx","outputId":"ecf2912c-76ae-479b-f594-091cdfdd9e77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of cpus: 80\n","torch.Size([2, 3, 15, 224, 224]) tensor([0, 0])\n"]}],"source":["BATCH_SIZE = 2\n","MAX_LEN = 15\n","IMAGE_SIZE = 224\n","\n","\n","transform = transforms.Compose(\n","    [\n","        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n","        transforms.ToTensor(),\n","    ]\n",")\n","\n","# Load dataset\n","train_dataset = VideoDataset(\n","    root_dir=\"./dataset/rwf-2000\", phase=\"train\", transform=transform, n_frames=MAX_LEN\n",")\n","\n","val_dataset = VideoDataset(\n","    root_dir=\"./dataset/rwf-2000\", phase=\"val\", transform=transform, n_frames=MAX_LEN\n",")\n","\n","# Count number of cpus\n","cpus = os.cpu_count()\n","print(f\"Number of cpus: {cpus}\")\n","\n","# Create data loaders\n","train_loader = DataLoader(\n","    train_dataset, batch_size=BATCH_SIZE, num_workers=cpus, shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset, batch_size=BATCH_SIZE, num_workers=cpus, shuffle=False\n",")\n","\n","# test\n","for data, label in train_loader:\n","    print(data.shape, label)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"N7O6uqHmHpyx"},"source":["# Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vX4xQ6A3Hpyx"},"outputs":[],"source":["def colorstr(*input):\n","    *args, string = input if len(input) > 1 else (\"blue\", \"bold\", input[0])\n","    colors = {\n","        \"black\": \"\\033[30m\",  # basic colors\n","        \"red\": \"\\033[31m\",\n","        \"green\": \"\\033[32m\",\n","        \"yellow\": \"\\033[33m\",\n","        \"blue\": \"\\033[34m\",\n","        \"magenta\": \"\\033[35m\",\n","        \"cyan\": \"\\033[36m\",\n","        \"white\": \"\\033[37m\",\n","        \"bright_black\": \"\\033[90m\",  # bright colors\n","        \"bright_red\": \"\\033[91m\",\n","        \"bright_green\": \"\\033[92m\",\n","        \"bright_yellow\": \"\\033[93m\",\n","        \"bright_blue\": \"\\033[94m\",\n","        \"bright_magenta\": \"\\033[95m\",\n","        \"bright_cyan\": \"\\033[96m\",\n","        \"bright_white\": \"\\033[97m\",\n","        \"end\": \"\\033[0m\",  # misc\n","        \"bold\": \"\\033[1m\",\n","        \"underline\": \"\\033[4m\",\n","    }\n","    return \"\".join(colors[x] for x in args) + f\"{string}\" + colors[\"end\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSDohGn6Hpyx"},"outputs":[],"source":["def train_model(\n","    model, train_loader, val_loader, criterion, optimizer, num_epochs=25, device=\"cuda\"\n","):\n","    \"\"\"\n","    Function to train the model.\n","\n","    Parameters:\n","    - model: The neural network model to train.\n","    - train_loader: DataLoader for the training set.\n","    - val_loader: DataLoader for the validation set.\n","    - criterion: The loss function.\n","    - optimizer: The optimization algorithm.\n","    - num_epochs: Number of epochs to train for.\n","    - device: The device to run the training on, 'cuda' or 'cpu'.\n","\n","    Returns:\n","    - model: The trained model.\n","    \"\"\"\n","    since = time.time()\n","\n","    history = {\n","        \"train_loss\": [],\n","        \"train_acc\": [],\n","        \"val_loss\": [],\n","        \"val_acc\": [],\n","        \"lr\": [],\n","    }\n","    best_val_acc = 0.0\n","\n","    # Send the model to the specified device\n","    model.to(device)\n","\n","    # Loop over the dataset multiple times\n","    for epoch in range(num_epochs):\n","        LOGGER.info(colorstr(f\"Epoch {epoch}/{num_epochs-1}:\"))\n","\n","        # Each epoch has a training and validation phase\n","        for phase in [\"train\", \"val\"]:\n","            if phase == \"train\":\n","                LOGGER.info(\n","                    colorstr(\"bright_yellow\", \"bold\", \"\\n%20s\" + \"%15s\" * 3)\n","                    % (\"Training:\", \"gpu_mem\", \"loss\", \"acc\")\n","                )\n","                model.train()\n","            else:\n","                LOGGER.info(\n","                    colorstr(\"bright_green\", \"bold\", \"\\n%20s\" + \"%15s\" * 3)\n","                    % (\"Validation:\", \"gpu_mem\", \"loss\", \"acc\")\n","                )\n","                model.eval()\n","\n","            running_items = 0\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Use the appropriate data loader\n","            data_loader = train_loader if phase == \"train\" else val_loader\n","\n","            _phase = tqdm(\n","                data_loader,\n","                total=len(data_loader),\n","                bar_format=\"{desc} {percentage:>7.0f}%|{bar:10}{r_bar}{bar:-10b}\",\n","                unit=\"batch\",\n","            )\n","\n","            # Iterate over data.\n","            for inputs, labels in _phase:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # Zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # Forward\n","                # Track history only in train\n","                with torch.set_grad_enabled(phase == \"train\"):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # Backward + optimize only if in training phase\n","                    if phase == \"train\":\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # Statistics\n","                running_items += outputs.size(0)\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","                epoch_loss = running_loss / running_items\n","                epoch_acc = running_corrects / running_items\n","\n","                mem = f\"{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}GB\"\n","                desc = (\"%35s\" + \"%15.6g\" * 2) % (\n","                    mem,\n","                    epoch_loss,\n","                    epoch_acc,\n","                )\n","                _phase.set_description_str(desc)\n","\n","            if phase == \"train\":\n","                history[\"train_loss\"].append(epoch_loss)\n","                history[\"train_acc\"].append(epoch_acc.item())\n","            else:\n","                history[\"val_loss\"].append(epoch_loss)\n","                history[\"val_acc\"].append(epoch_acc.item())\n","                if epoch_acc > best_val_acc:\n","                    best_val_acc = epoch_acc\n","                    history[\"best_epoch\"] = epoch\n","\n","                print(f\"Best val Acc: {best_val_acc:4f}\")\n","\n","    time_elapsed = time.time() - since\n","    history[\"INFO\"] = (\n","        \"Training complete in {:.0f}h {:.0f}m {:.0f}s with {} epochs - Best val Acc: {:4f}\".format(\n","            time_elapsed // 3600,\n","            time_elapsed % 3600 // 60,\n","            time_elapsed % 60,\n","            num_epochs,\n","            best_val_acc,\n","        )\n","    )\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1j9AmDUaHpyx","outputId":"cb018ee2-3a27-4d7c-c928-5989375a5eb3"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of VivitForVideoClassification were not initialized from the model checkpoint at google/vivit-b-16x2-kinetics400 and are newly initialized because the shapes did not match:\n","- vivit.embeddings.position_embeddings: found shape torch.Size([1, 3137, 768]) in the checkpoint and torch.Size([1, 1373, 768]) in the model instantiated\n","- classifier.weight: found shape torch.Size([400, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n","- classifier.bias: found shape torch.Size([400]) in the checkpoint and torch.Size([2]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[34m\u001b[1mEpoch 0/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.493009        0.77625     100%|██████████| 800/800 [03:48<00:00,  3.50batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.493019          0.785     100%|██████████| 200/200 [00:26<00:00,  7.48batch/s]\n","\u001b[34m\u001b[1mEpoch 1/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.785000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB       0.284058         0.8875     100%|██████████| 800/800 [03:50<00:00,  3.46batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.429285          0.815     100%|██████████| 200/200 [00:26<00:00,  7.45batch/s]\n","\u001b[34m\u001b[1mEpoch 2/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.815000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB        0.11948           0.96     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.516186          0.825     100%|██████████| 200/200 [00:26<00:00,  7.51batch/s]\n","\u001b[34m\u001b[1mEpoch 3/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0669346       0.975625     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB        0.64795            0.8     100%|██████████| 200/200 [00:26<00:00,  7.52batch/s]\n","\u001b[34m\u001b[1mEpoch 4/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0407663         0.9875     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.736764         0.7975     100%|██████████| 200/200 [00:26<00:00,  7.44batch/s]\n","\u001b[34m\u001b[1mEpoch 5/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0392338         0.9875     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.761056         0.7875     100%|██████████| 200/200 [00:26<00:00,  7.45batch/s]\n","\u001b[34m\u001b[1mEpoch 6/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0455792       0.985625     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.959702            0.8     100%|██████████| 200/200 [00:26<00:00,  7.50batch/s]\n","\u001b[34m\u001b[1mEpoch 7/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0329469        0.98875     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.788719         0.7975     100%|██████████| 200/200 [00:27<00:00,  7.40batch/s]\n","\u001b[34m\u001b[1mEpoch 8/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB     0.00339674              1     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.817275            0.8     100%|██████████| 200/200 [00:26<00:00,  7.44batch/s]\n","\u001b[34m\u001b[1mEpoch 9/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0503576        0.98375     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.648725         0.8175     100%|██████████| 200/200 [00:26<00:00,  7.41batch/s]\n","\u001b[34m\u001b[1mEpoch 10/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0308527           0.99     100%|██████████| 800/800 [03:50<00:00,  3.48batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.767059         0.7925     100%|██████████| 200/200 [00:26<00:00,  7.51batch/s]\n","\u001b[34m\u001b[1mEpoch 11/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0384502       0.985625     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.796227          0.805     100%|██████████| 200/200 [00:26<00:00,  7.41batch/s]\n","\u001b[34m\u001b[1mEpoch 12/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0174867         0.9925     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.973774          0.785     100%|██████████| 200/200 [00:26<00:00,  7.43batch/s]\n","\u001b[34m\u001b[1mEpoch 13/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB     0.00625249       0.998125     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.833754         0.8125     100%|██████████| 200/200 [00:26<00:00,  7.47batch/s]\n","\u001b[34m\u001b[1mEpoch 14/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0454068       0.985625     100%|██████████| 800/800 [03:50<00:00,  3.46batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.830386         0.8075     100%|██████████| 200/200 [00:26<00:00,  7.51batch/s]\n","\u001b[34m\u001b[1mEpoch 15/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0167301          0.995     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.806146         0.7975     100%|██████████| 200/200 [00:26<00:00,  7.48batch/s]\n","\u001b[34m\u001b[1mEpoch 16/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0180276          0.995     100%|██████████| 800/800 [03:50<00:00,  3.48batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.935627            0.8     100%|██████████| 200/200 [00:26<00:00,  7.47batch/s]\n","\u001b[34m\u001b[1mEpoch 17/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.825000\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0208631       0.993125     100%|██████████| 800/800 [03:49<00:00,  3.48batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.837694         0.8475     100%|██████████| 200/200 [00:26<00:00,  7.52batch/s]\n","\u001b[34m\u001b[1mEpoch 18/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.847500\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB      0.0268184         0.9925     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB       0.843478            0.8     100%|██████████| 200/200 [00:26<00:00,  7.41batch/s]\n","\u001b[34m\u001b[1mEpoch 19/19:\u001b[0m\n","\u001b[93m\u001b[1m\n","           Training:        gpu_mem           loss            acc\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.847500\n"]},{"name":"stderr","output_type":"stream","text":["                             8.23GB     0.00483894        0.99875     100%|██████████| 800/800 [03:50<00:00,  3.47batch/s]\n","\u001b[92m\u001b[1m\n","         Validation:        gpu_mem           loss            acc\u001b[0m\n","                             8.23GB         1.2326         0.7725     100%|██████████| 200/200 [00:27<00:00,  7.38batch/s]"]},{"name":"stdout","output_type":"stream","text":["Best val Acc: 0.847500\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Example usage (assuming you have defined your criterion and optimizer):\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = Model(num_classes=2, num_frames=15)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","\n","trained_model = train_model(\n","    model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device=device\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsqV5U5kHpyy"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"duc_open_sora","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}